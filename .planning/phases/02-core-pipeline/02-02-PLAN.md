---
phase: 02-core-pipeline
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/services/history.ts
  - src/services/intent.ts
  - src/services/ai.ts
  - src/services/whatsapp.ts
autonomous: true
requirements:
  - CORE-03
  - CORE-05
  - UX-01

must_haves:
  truths:
    - "Conversation history is loaded from the database as the last N messages, oldest-first, before any AI call"
    - "Intent is classified from the broker message text using keyword matching — zero latency, no external dependency"
    - "Bot returns a fallback 'não sei' message when intent is unknown or OpenAI returns an empty response"
    - "AI response is generated in Portuguese using conversation history as context"
    - "WhatsApp message delivery shows a typing indicator for 1-3 randomized seconds before the message appears"
    - "axios timeout on sendTextMessage is 20 seconds — enough to cover delayTyping duration"
  artifacts:
    - path: "src/services/history.ts"
      provides: "loadHistory(), saveMessage() functions"
      exports: ["loadHistory", "saveMessage"]
    - path: "src/services/intent.ts"
      provides: "classifyIntent() function and Intent type"
      exports: ["classifyIntent", "Intent"]
    - path: "src/services/ai.ts"
      provides: "generateResponse() function with system prompt and fallback"
      exports: ["generateResponse"]
    - path: "src/services/whatsapp.ts"
      provides: "sendTextMessage() extended with delayTyping + computeDelaySeconds()"
      exports: ["sendTextMessage", "computeDelaySeconds"]
  key_links:
    - from: "src/services/history.ts"
      to: "prisma.message"
      via: "prisma.message.findMany() with take + orderBy desc, then reversed"
      pattern: "prisma\\.message\\.findMany"
    - from: "src/services/ai.ts"
      to: "OpenAI Chat Completions"
      via: "openai.chat.completions.create()"
      pattern: "chat\\.completions\\.create"
    - from: "src/services/whatsapp.ts"
      to: "Z-API send-text"
      via: "delayTyping parameter in axios POST body"
      pattern: "delayTyping"
---

<objective>
Create the history, intent, AI, and WhatsApp typing indicator services — the AI and messaging layer of the Phase 2 pipeline.

Purpose: These four services turn a raw broker message + conversation history into an AI-generated Portuguese response with a humanized typing delay. They are fully independent of the contact/conversation services from Plan 01 and can be built in parallel.

Output: src/services/history.ts, src/services/intent.ts, src/services/ai.ts (new); src/services/whatsapp.ts (updated).
</objective>

<execution_context>
@/Users/felipescupino/.claude/get-shit-done/workflows/execute-plan.md
@/Users/felipescupino/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-core-pipeline/02-RESEARCH.md
@src/config.ts
@src/services/whatsapp.ts
@prisma/schema.prisma
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create history and intent services</name>
  <files>src/services/history.ts, src/services/intent.ts</files>
  <action>
Create src/services/history.ts:

```typescript
// src/services/history.ts
// Message history persistence and retrieval — CORE-04
import { prisma } from '../lib/prisma';
import { config } from '../config';

/**
 * Load the last N messages for a phone number, returned in chronological order (oldest-first).
 * ALWAYS call this BEFORE saving the current user message to avoid doubling the message in history.
 * N is controlled by HISTORY_LIMIT env var (default 20) via config.app.historyLimit.
 */
export async function loadHistory(phone: string) {
  const messages = await prisma.message.findMany({
    where: { phone },
    orderBy: { createdAt: 'desc' },
    take: config.app.historyLimit,
  });
  return messages.reverse();  // chronological order for LLM context
}

/**
 * Persist a single message (user or assistant) to the mensagens table.
 * Call for user message AFTER loadHistory, and for assistant message AFTER sendTextMessage succeeds.
 */
export async function saveMessage(
  phone: string,
  role: 'user' | 'assistant',
  content: string,
) {
  return prisma.message.create({
    data: { phone, role, content },
  });
}
```

Create src/services/intent.ts:

```typescript
// src/services/intent.ts
// Keyword-based intent classifier — CORE-03
// Interface: single function + type. Internals are swappable to GPT in Phase 5.

export type Intent = 'greeting' | 'qa' | 'quote' | 'handoff' | 'unknown';

// Keyword sets — order matters (handoff checked first to avoid 'seguro' matching as quote)
const HANDOFF_KEYWORDS = [
  '/humano', 'falar com humano', 'falar com uma pessoa', 'atendente',
  'pessoa real', 'quero falar com', 'preciso de um humano',
];
const QUOTE_KEYWORDS = [
  'cotar', 'cotação', 'cotacao', 'quero cotar', 'fazer uma cotação',
  'preciso de uma cotação',
];
const GREETING_KEYWORDS = [
  'oi', 'olá', 'ola', 'bom dia', 'boa tarde', 'boa noite',
  'hey', 'hello', 'tudo bem', 'tudo bom', 'e aí',
];

/**
 * Classify the broker's message into one of 5 intent buckets.
 * Returns 'unknown' only for very short/empty strings (≤3 chars).
 * Any non-trivial text that doesn't match specific keywords is treated as 'qa'.
 * NOTE: Do NOT expose the raw intent label in system prompts (leaks routing internals — see RESEARCH.md Pitfall 6).
 */
export function classifyIntent(text: string): Intent {
  const lower = text.toLowerCase().trim();
  if (HANDOFF_KEYWORDS.some((k) => lower.includes(k))) return 'handoff';
  if (QUOTE_KEYWORDS.some((k) => lower.includes(k))) return 'quote';
  if (GREETING_KEYWORDS.some((k) => lower.startsWith(k))) return 'greeting';
  if (lower.length > 3) return 'qa';  // any substantive text → Q&A attempt
  return 'unknown';
}
```

Note: `Intent` type is defined in and exported from `intent.ts` (not `src/types/index.ts`). Import it as `import { Intent } from './intent'` in ai.ts.
  </action>
  <verify>
    <automated>cd /Users/felipescupino/issy-assistant && npx tsc --noEmit 2>&1 | head -20</automated>
    <manual>Confirm history.ts loads with take+orderBy+reverse pattern; intent.ts defines Intent type and 5 keyword sets</manual>
  </verify>
  <done>Both files compile cleanly. loadHistory, saveMessage, classifyIntent, and Intent are exported. No TypeScript errors.</done>
</task>

<task type="auto">
  <name>Task 2: Create AI service and extend WhatsApp service with typing indicator</name>
  <files>src/services/ai.ts, src/services/whatsapp.ts</files>
  <action>
Create src/services/ai.ts:

```typescript
// src/services/ai.ts
// OpenAI Chat Completions service — CORE-05
// Uses SDK v4.104.0 (already installed): openai.chat.completions.create()
import OpenAI from 'openai';
import { config } from '../config';
import { Intent } from './intent';

const openai = new OpenAI({ apiKey: config.openai.apiKey });

/**
 * Generate an AI response for the broker using conversation history and current message.
 * Returns a fallback string if OpenAI returns empty content.
 *
 * IMPORTANT: historyMessages role must be cast — Prisma returns role as string,
 * but ChatCompletionMessageParam requires 'user' | 'assistant'. Cast is safe because
 * only 'user' and 'assistant' values are ever written by saveMessage().
 */
export async function generateResponse(
  contactName: string,
  historyMessages: Array<{ role: string; content: string }>,
  currentMessage: string,
  intent: Intent,
): Promise<string> {
  const systemPrompt = buildSystemPrompt(contactName, intent);

  const messages: OpenAI.Chat.ChatCompletionMessageParam[] = [
    { role: 'system', content: systemPrompt },
    ...historyMessages.map((m) => ({
      role: m.role as 'user' | 'assistant',
      content: m.content,
    })),
    { role: 'user', content: currentMessage },
  ];

  try {
    const completion = await openai.chat.completions.create({
      model: config.openai.model,
      messages,
      temperature: config.openai.temperature,
      max_tokens: config.openai.maxTokens,
    });

    return completion.choices[0]?.message?.content ?? getFallbackMessage();
  } catch (err) {
    console.error('[ai] Erro ao chamar OpenAI:', err);
    return getFallbackMessage();
  }
}

/**
 * Builds the system prompt. Intent is used internally to adjust focus instructions
 * but is NOT exposed verbatim to avoid leaking routing internals to the broker.
 * This function must remain a function (not a config string) — it grows in Phase 3.
 */
function buildSystemPrompt(contactName: string, intent: Intent): string {
  const intentContext = intent === 'quote'
    ? 'O corretor está interessado em fazer uma cotação. Colete informações necessárias e informe que o fluxo completo de cotação estará disponível em breve.'
    : intent === 'handoff'
    ? 'O corretor quer falar com um humano. Confirme que você vai transferir a conversa.'
    : intent === 'greeting'
    ? 'O corretor está iniciando uma conversa. Responda de forma acolhedora e pergunte como pode ajudar.'
    : 'Responda à pergunta do corretor com base em seu conhecimento sobre seguros.';

  return `Você é a Issy, assistente virtual da assessoria de seguros. Você ajuda corretores de seguros a responder dúvidas sobre produtos, coberturas e aceitação.

Corretor atual: ${contactName}
${intentContext}

Regras de comportamento:
- Responda SEMPRE em português brasileiro, tom profissional e conciso
- NUNCA invente valores de R$, coberturas específicas ou regras de aceitação — diga que não tem certeza e ofereça escalar para um humano
- Se não souber responder, diga exatamente: "Não tenho essa informação no momento. Posso transferir para um especialista da assessoria — deseja que eu faça isso?"
- Foque em: produtos de seguro (saúde, auto, vida, residencial, empresarial), coberturas, exclusões, aceitação
- Recuse educadamente qualquer assunto não relacionado a seguros
- Nunca responda como se fosse um humano — você é a Issy, assistente virtual`;
}

function getFallbackMessage(): string {
  return 'Desculpe, ocorreu um problema ao processar sua mensagem. Por favor, tente novamente em alguns instantes.';
}
```

Update src/services/whatsapp.ts to add `delayTyping` parameter and `computeDelaySeconds` helper. Replace the entire file content:

```typescript
// src/services/whatsapp.ts
// Z-API send-text service with native typing indicator — UX-01
// Source: https://developer.z-api.io/en/message/send-message-text

import axios from 'axios';
import { config } from '../config';

/**
 * Send a plain text message via Z-API with a typing indicator.
 * delayTypingSeconds (1-15): Z-API shows "typing..." to recipient for this duration
 * BEFORE delivering the message. This is the only way to show a typing indicator in Z-API
 * (there is no standalone presence-send endpoint).
 *
 * IMPORTANT: axios timeout must exceed delayTyping to avoid ETIMEDOUT.
 * Set to (delayTypingSeconds + 10) * 1000 as a flat safe ceiling of 20_000ms.
 *
 * @param phone - E.164 digits-only format, e.g. "5511999999999"
 * @param message - Plain text message body
 * @param delayTypingSeconds - Seconds to show typing indicator before delivery (default 2)
 */
export async function sendTextMessage(
  phone: string,
  message: string,
  delayTypingSeconds = 2,
): Promise<void> {
  const { instanceId, instanceToken, clientToken } = config.zapi;

  await axios.post(
    `https://api.z-api.io/instances/${instanceId}/token/${instanceToken}/send-text`,
    {
      phone,
      message,
      delayTyping: delayTypingSeconds,
    },
    {
      headers: { 'Client-Token': clientToken },
      timeout: 20_000,   // must exceed delayTyping; was 10_000 (insufficient for delays >= 2s)
    },
  );
}

/**
 * Compute a randomized delay in integer seconds from the configured ms bounds.
 * Used by the webhook pipeline to vary response timing naturally.
 */
export function computeDelaySeconds(): number {
  const minSec = Math.floor(config.app.humanDelayMinMs / 1000);
  const maxSec = Math.ceil(config.app.humanDelayMaxMs / 1000);
  return Math.floor(Math.random() * (maxSec - minSec + 1)) + minSec;
}
```

Key implementation notes:
- The `timeout: 20_000` replaces `10_000` — this is required (RESEARCH.md Pitfall 1: timeout shorter than delayTyping causes ETIMEDOUT)
- `computeDelaySeconds()` converts config ms values to integer seconds for Z-API
- `buildSystemPrompt` uses intent to adjust instructions but does NOT expose the raw intent label to the broker (RESEARCH.md Pitfall 6)
- The try/catch in `generateResponse` ensures OpenAI errors return the fallback message rather than crashing the pipeline
  </action>
  <verify>
    <automated>cd /Users/felipescupino/issy-assistant && npx tsc --noEmit 2>&1 | head -20</automated>
    <manual>Confirm ai.ts imports OpenAI SDK correctly; whatsapp.ts has delayTyping in request body and timeout: 20_000</manual>
  </verify>
  <done>Both files compile cleanly. generateResponse, computeDelaySeconds, and updated sendTextMessage are exported. No TypeScript errors.</done>
</task>

</tasks>

<verification>
Run TypeScript compiler check after both tasks complete:

```bash
cd /Users/felipescupino/issy-assistant && npx tsc --noEmit
```

Expected: zero TypeScript errors across all 4 new/updated files.

Spot-check key implementation details:
1. `history.ts` — `orderBy: { createdAt: 'desc' }` + `reverse()` (NOT `asc` — desc+reverse is the correct LIMIT pattern)
2. `intent.ts` — HANDOFF_KEYWORDS checked before QUOTE_KEYWORDS (prevents `/humano` matching quote path)
3. `ai.ts` — `role: m.role as 'user' | 'assistant'` cast on history messages
4. `whatsapp.ts` — `timeout: 20_000` (not 10_000)
</verification>

<success_criteria>
1. `src/services/history.ts` exports `loadHistory(phone)` and `saveMessage(phone, role, content)` using Prisma with configurable HISTORY_LIMIT
2. `src/services/intent.ts` exports `Intent` type and `classifyIntent(text)` with 5 keyword buckets
3. `src/services/ai.ts` exports `generateResponse()` using OpenAI SDK v4 with system prompt, history context, and fallback on error
4. `src/services/whatsapp.ts` updated: `sendTextMessage()` accepts `delayTypingSeconds` parameter; `computeDelaySeconds()` exported; axios timeout is 20_000ms
5. `npx tsc --noEmit` passes with zero errors
</success_criteria>

<output>
After completion, create `.planning/phases/02-core-pipeline/02-02-SUMMARY.md` with:
- Files created/modified
- Key implementation decisions (especially timeout fix and intent ordering)
- Any deviations from the plan
</output>
